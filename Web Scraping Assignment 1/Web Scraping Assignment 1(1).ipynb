{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c913f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 -> Wikipedia\n",
      "\n",
      "The Free Encyclopedia\n",
      "h2 -> 1 000 000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2 -> 100 000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2 -> 10 000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2 -> 1 000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2 -> 100+\n",
      "\n",
      "\n",
      "articles\n"
     ]
    }
   ],
   "source": [
    "#1 Python program to print all heading tags\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "link = 'https://www.wikipedia.org/'\n",
    "request = requests.get(link)\n",
    "Soup = BeautifulSoup(request.text, 'lxml')\n",
    "headingtags = [\"h1\", \"h2\", \"h3\",\"h4\",\"h5\",\"h6\"]\n",
    "for tags in Soup.find_all(headingtags):\n",
    "    print(tags.name + ' -> ' + tags.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad4412c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>year</th>\n",
       "      <th>imdb_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>(2021)</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>(1975)</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>(1991)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Oldeuboi</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    movie    year  imdb_rating\n",
       "0                 Spider-Man: No Way Home  (2021)          8.7\n",
       "1                           The Godfather  (1972)          9.2\n",
       "2                         The Dark Knight  (2008)          9.1\n",
       "3                The Shawshank Redemption  (1994)          9.3\n",
       "4                       Avengers: Endgame  (2019)          8.4\n",
       "..                                    ...     ...          ...\n",
       "95  Eternal Sunshine of the Spotless Mind  (2004)          8.3\n",
       "96                          The Lion King  (1994)          8.5\n",
       "97        One Flew Over the Cuckoo's Nest  (1975)          8.7\n",
       "98             Terminator 2: Judgment Day  (1991)          8.6\n",
       "99                               Oldeuboi  (2003)          8.4\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 Python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "# and make data frame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "titles = []\n",
    "years = []\n",
    "imdb_ratings = []\n",
    "pages = np.arange(1, 101, 50)\n",
    "for page in pages:\n",
    "    page = requests.get('https://www.imdb.com/search/title/?groups=top_100&ref_=adv_prv')\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "    sleep(randint(2,10))\n",
    "    for container in movie_div:\n",
    "        \n",
    "        name = container.h3.a.text\n",
    "        titles.append(name)\n",
    "        \n",
    "        year = container.h3.find('span', class_='lister-item-year').text\n",
    "        years.append(year)\n",
    "        \n",
    "        imdb = float(container.strong.text)\n",
    "        imdb_ratings.append(imdb)\n",
    "        \n",
    "movies = pd.DataFrame({'movie':titles,\n",
    "                       'year':years,\n",
    "                       'imdb_rating':imdb_ratings})\n",
    "\n",
    "movies         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d582ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release)\n",
    "# and make data frame\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "titles = []\n",
    "years = []\n",
    "imdb_ratings = []\n",
    "pages = np.arange(1, 101, 50)\n",
    "for page in pages:\n",
    "    page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "    sleep(randint(2,10))\n",
    "    for container in movie_div:\n",
    "        \n",
    "        name = container.h3.a.text\n",
    "        titles.append(name)\n",
    "        \n",
    "        year = container.h3.find('span', class_='lister-item-year').text\n",
    "        years.append(year)\n",
    "        \n",
    "        imdb = float(container.strong.text)\n",
    "        imdb_ratings.append(imdb)\n",
    "        \n",
    "movies = pd.DataFrame({'movie':titles,\n",
    "                       'year':years,\n",
    "                       'imdb_rating':imdb_ratings})\n",
    "\n",
    "movies    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4dc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Write a python program to scrape product name, price and discounts from \n",
    "#https://meesho.com/bags-ladies/pl/p7vbp\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get(\"https://meesho.com/bags-ladies/p1/p7vbp\")\n",
    "page\n",
    "soup=BeautifulSoup(page.content, \"html.parser\")\n",
    "product_name=soup.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\")\n",
    "products=[]\n",
    "for i in product_name:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    products.append(i)\n",
    "product_price=soup.find_all('h5',class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\")\n",
    "rate=[]\n",
    "for i in product_price:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    rate.append(i)\n",
    "product_discount=soup.find_all('span',class_=\"Text__StyledText-sc-oo0kvp-0 lnonyH\")\n",
    "discount=[]\n",
    "for i in product_discount:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    discount.append(i)\n",
    "data = pd.DataFrame({'Product name':products,\n",
    "                       'Product price':rate,\n",
    "                       'Product discount':discount})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 python program to scrape cricket rankings from icc-cricket.com for mens cricket\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "urls = [\n",
    "\"https://www.icc-cricket.com/rankings/mens/team-rankings/ODI\"\n",
    "\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\",\n",
    "\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"]\n",
    "\n",
    "final_result_file_name = \"All Ranking List.csv\"\n",
    "final_column_names = [\"Player Name\", \"Team Name\", \"Rating\"]\n",
    "pd.DataFrame(columns=final_column_names).to_csv(final_result_file_name, sep=\"\\t\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "for url in urls:\n",
    "    request_object = requests.get(url)\n",
    "    html_content = request_object.text\n",
    "    print(request_object.status_code, \"->\", url)\n",
    "    soup_object = BeautifulSoup(html_content, \"lxml\")\n",
    "    for element in soup_object.select('[class=\"ranking-pos up\"], [class=\"ranking-pos down\"]'):\n",
    "        element.replace_with(BeautifulSoup(\"<\" + element.name + \"></\" + element.name + \">\", \"html.parser\"))\n",
    "\n",
    "    ranking_type = soup_object.select_one(\".rankings-block__title-container > h4\").text\n",
    "\n",
    "    result_file_name = ranking_type + \".csv\"\n",
    "    column_names = [\"Position\", \"Player Name\", \"Team Name\", \"Rating\", \"Career Best Rating\", \"Crawl URL\"]\n",
    "    pd.DataFrame(columns=column_names).to_csv(result_file_name, sep=\"\\t\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    for element in soup_object.select('table[class=\"table rankings-table\"] tr'):\n",
    "        if(element.find(\"th\")):\n",
    "            continue\n",
    "        data_dict = dict()\n",
    "        data_dict[\"Crawl URL\"] = url\n",
    "        data_dict[\"Ranking Type\"] = ranking_type\n",
    "        if(element.select_one('[class*=\"position\"]')):\n",
    "            data_dict[\"Position\"] = element.select_one('[class*=\"position\"]').text\n",
    "        for player_name in (element.select('a[href*=\"/player-rankings\"]')):\n",
    "            if(player_name.text.strip()):\n",
    "                data_dict[\"Player Name\"] = player_name.text\n",
    "        if(element.select_one('[class^=\"flag-15\"]')):\n",
    "            data_dict[\"Team Name\"] = element.select_one('[class^=\"flag-15\"]')[\"class\"][-1]\n",
    "        if(element.select_one('[class$=\"rating\"]')):\n",
    "            data_dict[\"Rating\"] = element.select_one('[class$=\"rating\"]').text\n",
    "        if(element.select_one('td.u-hide-phablet')):\n",
    "            data_dict[\"Career Best Rating\"] = element.select_one('td.u-hide-phablet').text\n",
    "        for key in data_dict.keys():\n",
    "            data_dict[key] = re.sub(r\"\\s+\", \" \", data_dict[key])\n",
    "            data_dict[key] = data_dict[key].strip()\n",
    "        pd.DataFrame([data_dict], columns=column_names).to_csv(result_file_name, sep=\"\\t\", index=False, header=False, encoding=\"utf-8\", mode=\"a\")\n",
    "        pd.DataFrame([data_dict], columns=final_column_names).to_csv(final_result_file_name, sep=\"\\t\", index=False, header=False, encoding=\"utf-8\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b04b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 python program to scrape cricket rankings from icc-cricket.com for womens cricket\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "urls = [\n",
    "\"https://www.icc-cricket.com/rankings/womens/team-rankings/ODI\"\n",
    "\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\",,\n",
    "\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\",]\n",
    "\n",
    "final_result_file_name = \"All Ranking List.csv\"\n",
    "final_column_names = [\"Player Name\", \"Team Name\", \"Rating\"]\n",
    "pd.DataFrame(columns=final_column_names).to_csv(final_result_file_name, sep=\"\\t\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "for url in urls:\n",
    "    request_object = requests.get(url)\n",
    "    html_content = request_object.text\n",
    "    print(request_object.status_code, \"->\", url)\n",
    "    soup_object = BeautifulSoup(html_content, \"lxml\")\n",
    "    for element in soup_object.select('[class=\"ranking-pos up\"], [class=\"ranking-pos down\"]'):\n",
    "        element.replace_with(BeautifulSoup(\"<\" + element.name + \"></\" + element.name + \">\", \"html.parser\"))\n",
    "\n",
    "    ranking_type = soup_object.select_one(\".rankings-block__title-container > h4\").text\n",
    "\n",
    "    result_file_name = ranking_type + \".csv\"\n",
    "    column_names = [\"Position\", \"Player Name\", \"Team Name\", \"Rating\", \"Career Best Rating\", \"Crawl URL\"]\n",
    "    pd.DataFrame(columns=column_names).to_csv(result_file_name, sep=\"\\t\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    for element in soup_object.select('table[class=\"table rankings-table\"] tr'):\n",
    "        if(element.find(\"th\")):\n",
    "            continue\n",
    "        data_dict = dict()\n",
    "        data_dict[\"Crawl URL\"] = url\n",
    "        data_dict[\"Ranking Type\"] = ranking_type\n",
    "        if(element.select_one('[class*=\"position\"]')):\n",
    "            data_dict[\"Position\"] = element.select_one('[class*=\"position\"]').text\n",
    "        for player_name in (element.select('a[href*=\"/player-rankings\"]')):\n",
    "            if(player_name.text.strip()):\n",
    "                data_dict[\"Player Name\"] = player_name.text\n",
    "        if(element.select_one('[class^=\"flag-15\"]')):\n",
    "            data_dict[\"Team Name\"] = element.select_one('[class^=\"flag-15\"]')[\"class\"][-1]\n",
    "        if(element.select_one('[class$=\"rating\"]')):\n",
    "            data_dict[\"Rating\"] = element.select_one('[class$=\"rating\"]').text\n",
    "        if(element.select_one('td.u-hide-phablet')):\n",
    "            data_dict[\"Career Best Rating\"] = element.select_one('td.u-hide-phablet').text\n",
    "        for key in data_dict.keys():\n",
    "            data_dict[key] = re.sub(r\"\\s+\", \" \", data_dict[key])\n",
    "            data_dict[key] = data_dict[key].strip()\n",
    "        pd.DataFrame([data_dict], columns=column_names).to_csv(result_file_name, sep=\"\\t\", index=False, header=False, encoding=\"utf-8\", mode=\"a\")\n",
    "        pd.DataFrame([data_dict], columns=final_column_names).to_csv(final_result_file_name, sep=\"\\t\", index=False, header=False, encoding=\"utf-8\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24823f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 python program to scrape details of all the posts from coreyms.com\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "link = 'https://www.coreyms.com/'\n",
    "request = requests.get(link)\n",
    "Soup = BeautifulSoup(request.text, 'lxml')\n",
    "headingtags = [\"h1\", \"h2\", \"h3\",\"h4\",\"h5\",\"h6\"]\n",
    "for tags in Soup.find_all(headingtags):\n",
    "    print(tags.name + ' -> ' + tags.text.strip())\n",
    "data = [\"b\",\"div\",\"span\",\"p\"]\n",
    "for d in Soup.find_all(data):\n",
    "    print(d.name+ '-' + d.text.strip())\n",
    "links = [\"a href\"]\n",
    "for url in Soup.find_all(links):\n",
    "    print(url.name + '-' + url.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 python program to scrape house details from mentioned URL. It should include house title, location,\n",
    "#area, EMI and price from https://www.nobroker.in/\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get(\"https://www.nobroker.in/\")\n",
    "page\n",
    "soup=BeautifulSoup(page.content, \"html.parser\")\n",
    "area=soup.find_all('div',class_=\"productCardDetail\")\n",
    "areas=[]\n",
    "for i in area:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    areas.append(i)\n",
    "price=soup.find_all('div',class_=\"productPriceBox\")\n",
    "rates=[]\n",
    "for i in price:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    rates.append(i)\n",
    "emi=soup.find_all('div',class_=\"productCardImg false\")\n",
    "EMI=[]\n",
    "for i in emi:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    EMI.append(i)\n",
    "data = pd.DataFrame({'area':areas,\n",
    "                       'price':rates,\n",
    "                       'emi':EMI})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58059ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 python program to scrape first 10 product details which include product name , price , Image URL from\n",
    "#https://www.bewakoof.com/women-tshirts?ga_q=tshirts .\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get(\"https://www.bewakoof.com/women-tshirts?ga_q=tshirts\")\n",
    "page\n",
    "soup=BeautifulSoup(page.content, \"html.parser\")\n",
    "product_name=soup.find_all('div',class_=\"productCardDetail\")\n",
    "products=[]\n",
    "for i in product_name:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    products.append(i)\n",
    "product_price=soup.find_all('div',class_=\"productPriceBox\")\n",
    "rate=[]\n",
    "for i in product_price:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    rate.append(i)\n",
    "product_image=soup.find_all('div',class_=\"productCardImg false\")\n",
    "image=[]\n",
    "for i in product_image:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    image.append(i)\n",
    "data = pd.DataFrame({'Product name':products,\n",
    "                       'Product price':rate,\n",
    "                       'Product image':image})\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
