{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05102871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Python program to print all heading tags\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "link = 'https://www.wikipedia.org/'\n",
    "request = requests.get(link)\n",
    "Soup = BeautifulSoup(request.text, 'lxml')\n",
    "headingtags = [\"h1\", \"h2\", \"h3\",\"h4\",\"h5\",\"h6\"]\n",
    "for tags in Soup.find_all(headingtags):\n",
    "    print(tags.name + ' -> ' + tags.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bdfaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "# and make data frame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "titles = []\n",
    "years = []\n",
    "imdb_ratings = []\n",
    "pages = np.arange(1, 101, 50)\n",
    "for page in pages:\n",
    "    page = requests.get('https://www.imdb.com/search/title/?groups=top_100&ref_=adv_prv')\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "    sleep(randint(2,10))\n",
    "    for container in movie_div:\n",
    "        \n",
    "        name = container.h3.a.text\n",
    "        titles.append(name)\n",
    "        \n",
    "        year = container.h3.find('span', class_='lister-item-year').text\n",
    "        years.append(year)\n",
    "        \n",
    "        imdb = float(container.strong.text)\n",
    "        imdb_ratings.append(imdb)\n",
    "        \n",
    "movies = pd.DataFrame({'movie':titles,\n",
    "                       'year':years,\n",
    "                       'imdb_rating':imdb_ratings})\n",
    "\n",
    "movies        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9079aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release)\n",
    "# and make data frame\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "titles = []\n",
    "years = []\n",
    "imdb_ratings = []\n",
    "pages = np.arange(1, 101, 50)\n",
    "for page in pages:\n",
    "    page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "    sleep(randint(2,10))\n",
    "    for container in movie_div:\n",
    "        \n",
    "        name = container.h3.a.text\n",
    "        titles.append(name)\n",
    "        \n",
    "        year = container.h3.find('span', class_='lister-item-year').text\n",
    "        years.append(year)\n",
    "        \n",
    "        imdb = float(container.strong.text)\n",
    "        imdb_ratings.append(imdb)\n",
    "        \n",
    "movies = pd.DataFrame({'movie':titles,\n",
    "                       'year':years,\n",
    "                       'imdb_rating':imdb_ratings})\n",
    "\n",
    "movies    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce427fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://meesho.com/bags-ladies/pl/p7vbp')\n",
    "page\n",
    "soup=BeautifulSoup(page.content,\"html.parser\")\n",
    "print(soup.prettify())\n",
    "Product_name=soup.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\")\n",
    "Product_name\n",
    "Products=[]\n",
    "for i in Product_name:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Products.append(i)\n",
    "Products\n",
    "Product_price=soup.find_all('h5',class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\")\n",
    "Product_price\n",
    "Rate=[]\n",
    "for i in Product_price:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rate.append(i)\n",
    "Rate\n",
    "Product_discount=soup.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 fCJVtz NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm\")\n",
    "Product_discount\n",
    "\n",
    "Discount=[]\n",
    "for i in Product_discount:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Discount.append(i)\n",
    "Discount\n",
    "import pandas as pd\n",
    "data=pd.DataFrame()\n",
    "data[\"Product Name\"]=Products\n",
    "data[\"Product Price\"]=Rate\n",
    "data[\"Discount\"]=Discount\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--team-name\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__team\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player1=Player[0:10]\n",
    "Player1\n",
    "Team1=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--matches\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team1.append(i)\n",
    "\n",
    "Team2=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team2.append(i)\n",
    "Team3=Team2[0:18:2]\n",
    "Team4=Team1+Team3\n",
    "Points1=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--points\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Points1.append(i)\n",
    "\n",
    "Points2=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Points2.append(i)\n",
    "Points3=Points2[1:19:2]\n",
    "Points4=Points1+Points3\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "\n",
    "Rating1=Rating[0:10]\n",
    "print(len(Player1),len(Team1+Team3),len(Points1+Points3),len(Rating1))\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player1,'Team':Team4,'Points':Points4,'Rating':Rating1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefa06b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe743fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 b)Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player[0:10]\n",
    "\n",
    "Team=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "Team[0:10]\n",
    "\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "Rating[0:10]\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player,'Team':Team,'Rating':Rating})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee30af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player[0:10]\n",
    "\n",
    "Team=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "Team[0:10]\n",
    "\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "Rating[0:10]\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player,'Team':Team,'Rating':Rating})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--team-name\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__team\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player1=Player[0:10]\n",
    "Player1\n",
    "Team1=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--matches\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team1.append(i)\n",
    "\n",
    "Team2=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team2.append(i)\n",
    "Team3=Team2[0:18:2]\n",
    "Team4=Team1+Team3\n",
    "Points1=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--points\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Points1.append(i)\n",
    "\n",
    "Points2=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Points2.append(i)\n",
    "Points3=Points2[1:19:2]\n",
    "Points4=Points1+Points3\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "\n",
    "Rating1=Rating[0:10]\n",
    "print(len(Player1),len(Team1+Team3),len(Points1+Points3),len(Rating1))\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player1,'Team':Team4,'Points':Points4,'Rating':Rating1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player[0:10]\n",
    "\n",
    "Team=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "Team[0:10]\n",
    "\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "Rating[0:10]\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player,'Team':Team,'Rating':Rating})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player[0:10]\n",
    "\n",
    "Team=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "Team[0:10]\n",
    "\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "Rating[0:10]\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player,'Team':Team,'Rating':Rating})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab03c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://coreyms.com/')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Post_title=soup.find_all('a',class_=\"entry-title-link\")\n",
    "Post_title\n",
    "Title=[]\n",
    "for i in Post_title:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Title.append(i)\n",
    "Title1=Title[0:9]\n",
    "Title1\n",
    "Post_date=soup.find_all('time',class_=\"entry-time\")\n",
    "Post_date\n",
    "Date=[]\n",
    "for i in Post_date:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Date.append(i)\n",
    "Date1=Date[0:9]\n",
    "Date1\n",
    "Post_content=soup.find_all('div',class_=\"entry-content\")\n",
    "Post_content\n",
    "Content=[]\n",
    "for i in Post_content:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Content.append(i)\n",
    "Content1=Content[0:9]\n",
    "Content1\n",
    "Link=[]\n",
    "for i in soup.find_all('iframe',class_=\"youtube-player\"):\n",
    "    Link.append(i['src'])\n",
    "Link\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Title':Title1,'Date':Date1,'Content':Content1,'Link':Link})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e02716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Write a python program to scrape house details from mentioned URL. It should include house title, location, area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar,  Rajaji Nagar.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIiLCJzaG93TWFwIjpmYWxzZX0seyJsYXQiOjEyLjk3ODM2OTIsImxvbiI6NzcuNjQwODM1NiwicGxhY2VJZCI6IkNoSUprUU4zR0tRV3Jqc1JOaEJRSnJoR0Q3VSIsInBsYWNlTmFtZSI6IkluZGlyYW5hZ2FyIiwic2hvd01hcCI6ZmFsc2V9LHsibGF0IjoxMi45MDczODU5LCJsb24iOjc3LjU5OTM2NjgsInBsYWNlSWQiOiJDaElKLTR1QXNoc1ZyanNSRGNELVlfSEFJQlUiLCJwbGFjZU5hbWUiOiJKYXluYWdhcjNyZCBibG9jayIsInNob3dNYXAiOmZhbHNlfV0=&radius=2.0&city=bangalore&locality=Rajajinagar&type=BHK2')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "House_title=soup.find_all('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\")\n",
    "House_title\n",
    "Title=[]\n",
    "for i in House_title:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Title.append(i)\n",
    "Title\n",
    "House_location=soup.find_all('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\")\n",
    "House_location\n",
    "Location=[]\n",
    "for i in House_location:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Location.append(i)\n",
    "Location\n",
    "House_price=soup.find_all('div',class_=\"flex flex-col w-33pe items-center bo tp:w-half po:w-full border-r-0\")\n",
    "House_price\n",
    "Price=[]\n",
    "for i in House_price:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Price.append(i)\n",
    "Price\n",
    "House_EMI=soup.find_all('div',class_=\"flex flex-col w-33pe items-center border-r border-r-solid border-card-overview-border-color tp:w-half po:w-full last:border-r-1\")\n",
    "House_EMI\n",
    "EMI=[]\n",
    "for i in House_EMI:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    EMI.append(i)\n",
    "EMI1=EMI[1:10:2]\n",
    "House_area=soup.find_all('div',class_=\"font-semi-bold heading-6\")\n",
    "House_area\n",
    "Area=[]\n",
    "for i in House_area:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Area.append(i)\n",
    "Area1=Area[0:15:3]\n",
    "\n",
    "print(len(Title),len(Location),len(Price),len(EMI1),len(Area1))\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Title':Title,'Location':Location,'Price':Price,'EMI':EMI1,'Area':Area1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb14ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Write a python program to scrape mentioned details from dineout.co.in :\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.dineout.co.in/pune-restaurants/dineout-pay')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "title=soup.find_all('div',class_=\"restnt-info cursor\")\n",
    "title\n",
    "Title=[]\n",
    "for i in title:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Title.append(i)\n",
    "Title\n",
    "cusine=soup.find_all('span',class_=\"double-line-ellipsis\")\n",
    "cusine\n",
    "Cusine=[]\n",
    "for i in cusine:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Cusine.append(i)\n",
    "Cusine\n",
    "location=soup.find_all('div',class_=\"restnt-loc ellipsis\")\n",
    "location\n",
    "Location=[]\n",
    "for i in location:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Location.append(i)\n",
    "Location\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-rating rating-5\"):\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-rating rating-4\"): \n",
    "    Rating.append(i)\n",
    "Rating\n",
    "Image=[]\n",
    "for i in soup.find_all(\"img\",class_=\"no-img\"):\n",
    "    Image.append(i ['data-src'])\n",
    "Image\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Title':Title,'Cusine':Cusine,'Location':Location,'Rating':Rating,'Image':Image})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1658f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 Write a python program to scrape first 10 product details which include product name , price , Image URL from https://www.bewakoof.com/women-tshirts?ga_q=tshirts .\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.bewakoof.com/women-tshirts?ga_q=tshirts')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Name=[]\n",
    "for i in soup.find_all('div',class_=\"productCardDetail\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Name.append(i)\n",
    "Name\n",
    "Price=[]\n",
    "for i in soup.find_all('span',class_=\"discountedPriceText\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Price.append(i)\n",
    "Price\n",
    "Image=[]\n",
    "for i in soup.find_all('img',class_=\"productImgTag\"):\n",
    "    Image.append(i['src'])\n",
    "Image\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Name,'Price':Price,'Image':Image})\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
